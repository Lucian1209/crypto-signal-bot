# Crypto Signal ML Model Training
# Google Colab Notebook

# ===================================================================
# CELL 1: Setup and Install Dependencies
# ===================================================================

!pip install -q python-binance pandas-ta vaderSentiment tensorflow scikit-learn

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

print(f"TensorFlow version: {tf.__version__}")
print(f"GPU Available: {tf.config.list_physical_devices('GPU')}")

# ===================================================================
# CELL 2: Data Collection
# ===================================================================

# Mount Google Drive (optional - to save data)
from google.colab import drive
drive.mount('/content/drive')

# Import data collectors
# (Upload binance_collector.py and sentiment_collector.py to Colab)
from binance_collector import BinanceCollector
from sentiment_collector import SentimentCollector

# Initialize collectors
binance = BinanceCollector()

# Sentiment collector (optional - Twitter and News)
# Get API keys from:
# Twitter: https://developer.twitter.com/
# NewsAPI: https://newsapi.org/
sentiment = SentimentCollector(
    twitter_bearer_token=None,  # Optional: add your Twitter bearer token
    newsapi_key=None             # Optional: add your NewsAPI key
)

# Collect data
symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT"]
all_data = {}

for symbol in symbols:
    print(f"\n{'='*60}")
    print(f"Collecting data for {symbol}")
    print('='*60)

    # Technical data
    df = binance.get_historical_data(symbol, interval="1h", days_back=90)
    df = binance.calculate_technical_indicators(df)

    # Note: Sentiment collection would go here
    # For now, we'll work with technical indicators only

    all_data[symbol] = df
    print(f"âœ… Collected {len(df)} rows for {symbol}")

# ===================================================================
# CELL 3: Feature Engineering & Target Creation
# ===================================================================

def create_targets(df, future_periods=4, profit_threshold=0.02):
    """
    Create trading targets:
    1 = BUY (price will go up > profit_threshold in next future_periods)
    0 = HOLD/SELL (price won't reach profit threshold)
    """
    df = df.copy()

    # Calculate future return
    df['future_price'] = df['close'].shift(-future_periods)
    df['future_return'] = (df['future_price'] - df['close']) / df['close']

    # Create binary target
    df['target'] = (df['future_return'] > profit_threshold).astype(int)

    # Remove rows where we don't have future data
    df.dropna(subset=['future_price'], inplace=True)

    return df

# Apply to all symbols
for symbol, df in all_data.items():
    all_data[symbol] = create_targets(df, future_periods=4, profit_threshold=0.015)

    print(f"{symbol}:")
    print(f"  Total samples: {len(df)}")
    print(f"  BUY signals: {df['target'].sum()} ({df['target'].mean()*100:.1f}%)")
    print(f"  SELL/HOLD signals: {(1-df['target']).sum()} ({(1-df['target'].mean())*100:.1f}%)")

# Combine all symbols
combined_df = pd.concat([all_data[s] for s in symbols], ignore_index=True)
print(f"\nâœ… Combined dataset: {len(combined_df)} samples")

# ===================================================================
# CELL 4: Prepare Data for LSTM
# ===================================================================

# Select features
feature_columns = [
    'open', 'high', 'low', 'close', 'volume',
    'rsi', 'macd', 'macd_signal', 'macd_histogram',
    'bb_upper', 'bb_middle', 'bb_lower',
    'ema_9', 'ema_21', 'ema_50',
    'atr', 'stoch_k', 'stoch_d',
    'price_change_1h', 'price_change_24h'
]

# Ensure all features exist
available_features = [col for col in feature_columns if col in combined_df.columns]
print(f"Using {len(available_features)} features: {available_features}")

X = combined_df[available_features].values
y = combined_df['target'].values

# Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Create sequences for LSTM
def create_sequences(X, y, sequence_length=24):
    """Create sequences for LSTM input"""
    X_seq, y_seq = [], []

    for i in range(len(X) - sequence_length):
        X_seq.append(X[i:i+sequence_length])
        y_seq.append(y[i+sequence_length])

    return np.array(X_seq), np.array(y_seq)

sequence_length = 24  # Use last 24 hours to predict
X_sequences, y_sequences = create_sequences(X_scaled, y, sequence_length)

print(f"Sequence shape: {X_sequences.shape}")
print(f"Target shape: {y_sequences.shape}")

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X_sequences, y_sequences, test_size=0.2, random_state=42, shuffle=False
)

print(f"Train: {X_train.shape}, Test: {X_test.shape}")

# ===================================================================
# CELL 5: Build LSTM Model
# ===================================================================

def build_lstm_model(input_shape, units=128):
    """Build LSTM model for signal prediction"""

    model = keras.Sequential([
        # LSTM layers
        layers.LSTM(units, return_sequences=True, input_shape=input_shape),
        layers.Dropout(0.2),

        layers.LSTM(units//2, return_sequences=True),
        layers.Dropout(0.2),

        layers.LSTM(units//4),
        layers.Dropout(0.2),

        # Dense layers
        layers.Dense(64, activation='relu'),
        layers.Dropout(0.2),

        layers.Dense(32, activation='relu'),

        # Output layer (binary classification)
        layers.Dense(1, activation='sigmoid')
    ])

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]
    )

    return model

# Build model
model = build_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))
model.summary()

# ===================================================================
# CELL 6: Train Model
# ===================================================================

# Callbacks
early_stopping = keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

reduce_lr = keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=0.00001
)

# Train
history = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=50,
    batch_size=32,
    callbacks=[early_stopping, reduce_lr],
    verbose=1
)

# ===================================================================
# CELL 7: Evaluate Model
# ===================================================================

# Plot training history
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

axes[0, 0].plot(history.history['loss'], label='Train Loss')
axes[0, 0].plot(history.history['val_loss'], label='Val Loss')
axes[0, 0].set_title('Loss')
axes[0, 0].legend()

axes[0, 1].plot(history.history['accuracy'], label='Train Accuracy')
axes[0, 1].plot(history.history['val_accuracy'], label='Val Accuracy')
axes[0, 1].set_title('Accuracy')
axes[0, 1].legend()

axes[1, 0].plot(history.history['precision'], label='Train Precision')
axes[1, 0].plot(history.history['val_precision'], label='Val Precision')
axes[1, 0].set_title('Precision')
axes[1, 0].legend()

axes[1, 1].plot(history.history['recall'], label='Train Recall')
axes[1, 1].plot(history.history['val_recall'], label='Val Recall')
axes[1, 1].set_title('Recall')
axes[1, 1].legend()

plt.tight_layout()
plt.show()

# Predictions
y_pred_proba = model.predict(X_test)
y_pred = (y_pred_proba > 0.5).astype(int).flatten()

# Metrics
print("\n" + "="*60)
print("MODEL EVALUATION")
print("="*60)
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=['SELL/HOLD', 'BUY']))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# ===================================================================
# CELL 8: Save Model
# ===================================================================

# Save model
model_path = '/content/drive/MyDrive/crypto_signal_model.h5'
model.save(model_path)
print(f"âœ… Model saved to {model_path}")

# Save scaler
import joblib
scaler_path = '/content/drive/MyDrive/scaler.pkl'
joblib.dump(scaler, scaler_path)
print(f"âœ… Scaler saved to {scaler_path}")

# Save feature names
import json
features_path = '/content/drive/MyDrive/feature_names.json'
with open(features_path, 'w') as f:
    json.dump(available_features, f, indent=2)
print(f"âœ… Feature names saved to {features_path}")

print("\nðŸ“¦ All files saved! You can now download:")
print(f"1. {model_path}")
print(f"2. {scaler_path}")
print(f"3. {features_path}")

# Also save locally for immediate download
print("\nðŸ’¾ Saving local copies for download...")
model.save('crypto_signal_model.h5')
joblib.dump(scaler, 'scaler.pkl')
with open('feature_names.json', 'w') as f:
    json.dump(available_features, f, indent=2)

print("\nâœ… Local files created. Click on folder icon ðŸ“ to download:")
print("   - crypto_signal_model.h5")
print("   - scaler.pkl")
print("   - feature_names.json")

# ===================================================================
# CELL 9: Test Real-Time Prediction
# ===================================================================

def predict_signal(model, scaler, symbol="BTCUSDT", sequence_length=24):
    """Test real-time prediction"""

    # Get latest data
    df = binance.get_historical_data(symbol, interval="1h", days_back=2)
    df = binance.calculate_technical_indicators(df)

    # Get last sequence
    X_latest = df[available_features].values[-sequence_length:]
    X_scaled = scaler.transform(X_latest)
    X_seq = X_scaled.reshape(1, sequence_length, len(available_features))

    # Predict
    prediction_proba = model.predict(X_seq)[0][0]
    prediction = "BUY" if prediction_proba > 0.5 else "SELL/HOLD"

    return {
        'symbol': symbol,
        'prediction': prediction,
        'confidence': float(prediction_proba),
        'timestamp': datetime.now().isoformat()
    }

# Test
signal = predict_signal(model, scaler, "BTCUSDT")
print("\nðŸŽ¯ Real-time Signal:")
print(f"Symbol: {signal['symbol']}")
print(f"Prediction: {signal['prediction']}")
print(f"Confidence: {signal['confidence']:.2%}")
